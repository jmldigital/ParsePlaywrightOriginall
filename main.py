"""
–ü–∞—Ä—Å–µ—Ä –Ω–∞ Crawlee - –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
- –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Crawlee session persistence
- URL –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–Ω–µ—Å–µ–Ω–∞ –∏–∑ —Å–∫—Ä–µ–π–ø–µ—Ä–æ–≤
- –°–∫—Ä–µ–π–ø–µ—Ä—ã –¥–µ–ª–∞—é—Ç —Ç–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥ DOM
"""

import asyncio
import sys
import io
import os
from pathlib import Path
import pandas as pd
from dotenv import load_dotenv

import asyncio
import sys
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
from crawlee import Request, ConcurrencySettings

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û:
from crawlee.crawlers import PlaywrightCrawler, PlaywrightCrawlingContext
from crawlee import Request

# UTF-8 setup
sys.stdout.reconfigure(encoding="utf-8")
sys.stderr.reconfigure(encoding="utf-8")
if os.name == "nt":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")
os.environ["PYTHONIOENCODING"] = "utf-8"

load_dotenv()

from config import (
    INPUT_FILE,
    MAX_ROWS,
    MAX_WORKERS,
    INPUT_COL_BRAND,
    INPUT_COL_ARTICLE,
    ENABLE_NAME_PARSING,
    ENABLE_WEIGHT_PARSING,
    ENABLE_PRICE_PARSING,
    AVTO_LOGIN,
    AVTO_PASSWORD,
    BAD_DETAIL_NAMES,
    SELECTORS,
    get_output_file,
    reload_config,
    TEMP_RAW,
)
from utils import logger, preprocess_dataframe, consolidate_weights
from captcha_manager import CaptchaManager

# –ò–º–ø–æ—Ä—Ç –¢–û–õ–¨–ö–û –ø–∞—Ä—Å–µ—Ä–æ–≤ (–±–µ–∑ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏)
from scraper_japarts_pure import parse_weight_japarts
from scraper_armtek_pure import parse_weight_armtek
from scraper_stparts_pure import parse_stparts_name, parse_stparts_price
from scraper_avtoformula_pure import parse_avtoformula_name, parse_avtoformula_price
from price_adjuster import adjust_prices_and_save


# ===================== URL –ì–ï–ù–ï–†–ê–¢–û–†–´ =====================
class SiteUrls:
    """–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ URL –¥–ª—è –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤"""

    @staticmethod
    def japarts_search(part: str) -> str:
        return f"https://www.japarts.ru/?id=price&search={part}"

    @staticmethod
    def armtek_search(part: str) -> str:
        return f"https://armtek.ru/search?text={part}"

    @staticmethod
    def stparts_search(part: str) -> str:
        return f"https://stparts.ru/search/?text={part}"

    @staticmethod
    def avtoformula_search(brand: str, part: str) -> str:
        # Avtoformula –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–æ—Ä–º—É –Ω–∞ –≥–ª–∞–≤–Ω–æ–π, –ø–æ—ç—Ç–æ–º—É URL = –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
        # –ü–æ–∏—Å–∫ –±—É–¥–µ—Ç —á–µ—Ä–µ–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã –≤ –ø–∞—Ä—Å–µ—Ä–µ
        return "https://www.avtoformula.ru"


# ===================== –£–ü–†–û–©–ï–ù–ù–ê–Ø –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø =====================
class SimpleAuth:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Crawlee session"""

    @staticmethod
    async def login_avtoformula(page) -> bool:
        """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ª–æ–≥–∏–Ω–∞ - Crawlee —Å–∞–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç —Å–µ—Å—Å–∏—é"""
        try:
            await page.goto("https://www.avtoformula.ru")

            # –ü—Ä–æ–≤–µ—Ä–∫–∞: —É–∂–µ –∑–∞–ª–æ–≥–∏–Ω–µ–Ω—ã?
            if await page.locator("span:has-text('–í—ã –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –∫–∞–∫')").count() > 0:
                logger.info("‚úÖ –£–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã")
                return True

            # –õ–æ–≥–∏–Ω
            await page.fill(f"#{SELECTORS['avtoformula']['login_field']}", AVTO_LOGIN)
            await page.fill(
                f"#{SELECTORS['avtoformula']['password_field']}", AVTO_PASSWORD
            )
            await page.click(SELECTORS["avtoformula"]["login_button"])

            # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            await page.wait_for_selector(
                f"#{SELECTORS['avtoformula']['login_field']}",
                state="hidden",
                timeout=10000,
            )

            # –†–µ–∂–∏–º A0 (–±–µ–∑ –∞–Ω–∞–ª–æ–≥–æ–≤)
            await page.select_option(
                f"#{SELECTORS['avtoformula']['smode_select']}", "A0"
            )

            logger.info("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
            return True

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return False


# ===================== –ì–õ–ê–í–ù–´–ô –ö–õ–ê–°–° =====================
class ParserCrawler:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–∞ Crawlee"""

    def __init__(self):
        self.df = None
        self.mode = None
        self.captcha_manager = CaptchaManager()
        self.results_lock = asyncio.Lock()
        self.processed_count = 0
        self.total_tasks = 0

        # üÜï –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∞–π—Ç–∞–º
        self.stats = {
            "japarts": {"total": 0, "success": 0, "empty": 0},
            "armtek": {"total": 0, "success": 0, "empty": 0},
        }

    async def setup(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        reload_config()

        # –†–µ–∂–∏–º
        active = sum([ENABLE_WEIGHT_PARSING, ENABLE_NAME_PARSING, ENABLE_PRICE_PARSING])
        if active != 1:
            raise ValueError("‚ùå –¢–æ–ª—å–∫–æ 1 —Ä–µ–∂–∏–º!")

        self.mode = (
            "–í–ï–°–ê"
            if ENABLE_WEIGHT_PARSING
            else "–ò–ú–ï–ù–ê" if ENABLE_NAME_PARSING else "–¶–ï–ù–´"
        )

        logger.info(f"‚úÖ –†–µ–∂–∏–º: {self.mode}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.df = pd.read_excel(INPUT_FILE)
        self.df = preprocess_dataframe(self.df)
        self._init_columns()

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.df)} —Å—Ç—Ä–æ–∫")

    def _init_columns(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫"""
        from config import (
            stparts_price,
            stparts_delivery,
            avtoformula_price,
            avtoformula_delivery,
            JPARTS_P_W,
            JPARTS_V_W,
            ARMTEK_P_W,
            ARMTEK_V_W,
        )

        cols = [
            stparts_price,
            stparts_delivery,
            avtoformula_price,
            avtoformula_delivery,
        ]
        for col in cols:
            if col not in self.df.columns:
                self.df[col] = None

        if ENABLE_NAME_PARSING and "finde_name" not in self.df.columns:
            self.df["finde_name"] = None

        if ENABLE_WEIGHT_PARSING:
            for col in [JPARTS_P_W, JPARTS_V_W, ARMTEK_P_W, ARMTEK_V_W]:
                if col not in self.df.columns:
                    self.df[col] = None

    async def request_handler(self, context: PlaywrightCrawlingContext):
        """
        –û–±—Ä–∞–±–æ—Ç—á–∏–∫ Crawlee - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Request
        –ü–æ–ª—É—á–∞–µ—Ç –£–ñ–ï –æ—Ç–∫—Ä—ã—Ç—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –Ω—É–∂–Ω—ã–º URL
        """
        page = context.page
        request = context.request

        idx = request.user_data["idx"]
        brand = request.user_data["brand"]
        part = request.user_data["part"]
        site = request.user_data["site"]
        task_type = request.user_data["task_type"]  # "weight"/"name"/"price"

        # üî• –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø (–µ—Å–ª–∏ Avtoformula)
        if site == "avtoformula" and not hasattr(self, "_avtoformula_logged_in"):
            logger.info("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è Avtoformula...")
            success = await SimpleAuth.login_avtoformula(page)
            if success:
                self._avtoformula_logged_in = True
            else:
                raise Exception("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")

        # logger.info(f"üîç [{idx}] {site}: {part}")

        try:
            # –í—ã–±–æ—Ä –ø–∞—Ä—Å–µ—Ä–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∞–π—Ç–∞ –∏ –∑–∞–¥–∞—á–∏
            result = await self._route_to_parser(
                page, idx, brand, part, site, task_type
            )

            if result:
                await self._save_result(idx, result)

            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            async with self.results_lock:
                self.processed_count += 1
                if self.processed_count % TEMP_RAW / 2 == 0:
                    logger.info(f"üìä {self.processed_count}/{self.total_tasks}")

        except Exception as e:
            logger.error(f"‚ùå [{idx}] {site}: {e}")
            # Crawlee –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç

    async def _route_to_parser(self, page, idx, brand, part, site, task_type):
        """–†–æ—É—Ç–∏–Ω–≥ –∫ –Ω—É–∂–Ω–æ–º—É –ø–∞—Ä—Å–µ—Ä—É"""

        # ======== –í–ï–°–ê ========
        if task_type == "weight":
            if site == "japarts":
                physical, volumetric = await parse_weight_japarts(page, part, logger)

                if physical == "NeedCaptcha":
                    if await self._solve_captcha(page, "japarts"):
                        physical, volumetric = await parse_weight_japarts(
                            page, part, logger
                        )

                from config import JPARTS_P_W, JPARTS_V_W

                # üÜï –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if physical or volumetric:
                    self.stats["japarts"]["success"] += 1
                    logger.info(f"[JAPARTS] ‚úÖ {part} | P={physical} | V={volumetric}")
                else:
                    self.stats["japarts"]["empty"] += 1
                    logger.info(f"[JAPARTS] ‚ö†Ô∏è {part} | –ù–µ –Ω–∞–π–¥–µ–Ω–æ")

                # üÜï –î–û–ë–ê–í–ò–¢–¨ –ª–æ–≥ –î–û return:
                # logger.info(
                #     f"üîç [{idx}] Japarts RESULT ‚Üí {JPARTS_P_W}={physical}, {JPARTS_V_W}={volumetric}"
                # )

                return {JPARTS_P_W: physical, JPARTS_V_W: volumetric}

            elif site == "armtek":
                physical, volumetric = await parse_weight_armtek(page, part, logger)

                # üî• RateLimit –æ–±—Ä–∞–±–æ—Ç–∫–∞
                if physical == "NeedProxy":
                    logger.warning(f"üö¶ [{idx}] RateLimit –Ω–∞ Armtek ‚Üí –ø—Ä–æ–∫—Å–∏ retry")
                    return await self._retry_with_proxy(
                        idx, brand, part, site, task_type
                    )

                if physical == "NeedCaptcha":
                    if await self._solve_captcha(page, "armtek"):
                        physical, volumetric = await parse_weight_armtek(
                            page, part, logger
                        )

                # üî• 1. CLOUDFLARE - —Å–±—Ä–æ—Å–∏—Ç—å –ø—Ä–æ–∫—Å–∏, retry –±–µ–∑ –ø—Ä–æ–∫—Å–∏
                if physical == "CloudFlare":
                    logger.warning(f"‚òÅÔ∏è [{idx}] CloudFlare –Ω–∞ Armtek ‚Üí retry –±–µ–∑ –ø—Ä–æ–∫—Å–∏")

                    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (Crawlee —É–∂–µ –±–µ–∑ –ø—Ä–æ–∫—Å–∏)
                    try:
                        await page.reload(wait_until="domcontentloaded", timeout=30000)
                        await page.wait_for_timeout(3000)  # –ñ–¥—ë–º CloudFlare check

                        # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                        physical, volumetric = await parse_weight_armtek(
                            page, part, logger
                        )

                        # –ï—Å–ª–∏ —Å–Ω–æ–≤–∞ CloudFlare - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        if physical == "CloudFlare":
                            logger.error(f"‚òÅÔ∏è [{idx}] CloudFlare –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–µ–Ω ‚Üí –ø—Ä–æ–ø—É—Å–∫")
                            self.stats["armtek"]["empty"] += 1
                            from config import ARMTEK_P_W, ARMTEK_V_W

                            return {ARMTEK_P_W: None, ARMTEK_V_W: None}

                    except Exception as e:
                        logger.error(f"‚ùå [{idx}] –û—à–∏–±–∫–∞ retry CloudFlare: {e}")
                        self.stats["armtek"]["empty"] += 1
                        from config import ARMTEK_P_W, ARMTEK_V_W

                        return {ARMTEK_P_W: None, ARMTEK_V_W: None}

                from config import ARMTEK_P_W, ARMTEK_V_W

                # üÜï –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if physical or volumetric:
                    self.stats["armtek"]["success"] += 1
                    logger.info(f"[ARMTEK] ‚úÖ {part} | P={physical} | V={volumetric}")
                else:
                    self.stats["armtek"]["empty"] += 1
                    logger.info(f"[ARMTEK] ‚ö†Ô∏è {part} | –ù–µ –Ω–∞–π–¥–µ–Ω–æ")

                return {ARMTEK_P_W: physical, ARMTEK_V_W: volumetric}

        # ======== –ò–ú–ï–ù–ê ========
        elif task_type == "name":
            if site == "stparts":
                name = await parse_stparts_name(page, part, logger)

                if name == "NeedCaptcha":
                    if await self._solve_captcha(page, "stparts"):
                        name = await parse_stparts_name(page, part, logger)

                return (
                    {"finde_name": name}
                    if name and name not in BAD_DETAIL_NAMES
                    else None
                )

            elif site == "avtoformula":
                name = await parse_avtoformula_name(page, part, logger)

                if name == "NeedCaptcha":
                    if await self._solve_captcha(page, "avtoformula"):
                        name = await parse_avtoformula_name(page, part, logger)

                return {
                    "finde_name": (
                        name if name and name not in BAD_DETAIL_NAMES else "Detail"
                    )
                }

        # ======== –¶–ï–ù–´ ========
        elif task_type == "price":
            from config import (
                stparts_price,
                stparts_delivery,
                avtoformula_price,
                avtoformula_delivery,
            )

            if site == "stparts":
                price, delivery = await parse_stparts_price(page, brand, part, logger)
                return {stparts_price: price, stparts_delivery: delivery}

            elif site == "avtoformula":
                price, delivery = await parse_avtoformula_price(
                    page, brand, part, logger
                )
                return {avtoformula_price: price, avtoformula_delivery: delivery}

        return None

    async def _solve_captcha(self, page, site_key):
        """–†–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏"""
        logger.info(f"üîí –ö–∞–ø—á–∞ {site_key}")

        success = await self.captcha_manager.solve_captcha(
            page=page,
            logger=logger,
            site_key=site_key,
            selectors=SELECTORS.get(site_key, {}),
        )

        logger.info(f"{'‚úÖ' if success else '‚ùå'} –ö–∞–ø—á–∞ {site_key}")
        return success

    # async def _retry_with_proxy(self, idx, brand, part, site, task_type):
    #     """
    #     üÜï Retry —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ –ø—Ä–∏ RateLimit
    #     –°–æ–∑–¥–∞—ë—Ç –ù–û–í–´–ô –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –ø—Ä–æ–∫—Å–∏ –¥–ª—è –û–î–ù–û–ì–û –∑–∞–ø—Ä–æ—Å–∞
    #     """
    #     from utils import get_2captcha_proxy

    #     try:
    #         # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –æ—Ç 2Captcha
    #         proxy_config = get_2captcha_proxy()
    #         logger.info(f"üîÑ [{idx}] Retry —Å –ø—Ä–æ–∫—Å–∏: {proxy_config['server'][:30]}...")

    #         # üî• Crawlee –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã!
    #         # –ò—Å–ø–æ–ª—å–∑—É–µ–º browser –∏–∑ crawler
    #         temp_browser = self.crawler.browser_pool._browser  # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –¥–æ—Å—Ç—É–ø

    #         # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –ø—Ä–æ–∫—Å–∏
    #         proxy_context = await temp_browser.new_context(
    #             proxy=proxy_config,
    #             viewport={"width": 1920, "height": 1080},
    #             user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    #         )

    #         # –ù–æ–≤–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
    #         proxy_page = await proxy_context.new_page()

    #         try:
    #             # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ URL
    #             url = SiteUrls.armtek_search(part)  # –¢–æ–ª—å–∫–æ Armtek –∏–º–µ–µ—Ç RateLimit
    #             await proxy_page.goto(url, wait_until="domcontentloaded", timeout=60000)

    #             # –ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
    #             from scraper_armtek_pure import parse_weight_armtek

    #             physical, volumetric = await parse_weight_armtek(
    #                 proxy_page, part, logger
    #             )

    #             logger.info(f"‚úÖ [{idx}] Proxy retry —É—Å–ø–µ—à–µ–Ω: {physical}/{volumetric}")

    #             from config import ARMTEK_P_W, ARMTEK_V_W

    #             return {ARMTEK_P_W: physical, ARMTEK_V_W: volumetric}

    #         finally:
    #             # Cleanup
    #             await proxy_page.close()
    #             await proxy_context.close()

    #     except Exception as e:
    #         logger.error(f"‚ùå [{idx}] Proxy retry failed: {e}")
    #         from config import ARMTEK_P_W, ARMTEK_V_W

    #         return {ARMTEK_P_W: None, ARMTEK_V_W: None}

    async def _retry_with_proxy(self, idx, brand, part, site, task_type):
        """Retry —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ –ø—Ä–∏ RateLimit"""
        from utils import get_2captcha_proxy
        from playwright.async_api import async_playwright  # üÜï –î–æ–±–∞–≤–∏—Ç—å –∏–º–ø–æ—Ä—Ç

        try:
            proxy_config = get_2captcha_proxy()
            logger.info(f"üîÑ [{idx}] Retry —Å –ø—Ä–æ–∫—Å–∏: {proxy_config['server'][:30]}...")

            # üÜï –°–æ–∑–¥–∞—ë–º –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π Playwright –∫–æ–Ω—Ç–µ–∫—Å—Ç
            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=True, proxy=proxy_config  # ‚úÖ –ü–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å —Å—é–¥–∞!
                )
                context = await browser.new_context(
                    viewport={"width": 1920, "height": 1080},
                    user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                )
                page = await context.new_page()

                try:
                    url = SiteUrls.armtek_search(part)
                    await page.goto(url, wait_until="domcontentloaded", timeout=60000)

                    from scraper_armtek_pure import parse_weight_armtek

                    physical, volumetric = await parse_weight_armtek(page, part, logger)

                    logger.info(f"‚úÖ [{idx}] Proxy retry: {physical}/{volumetric}")

                    from config import ARMTEK_P_W, ARMTEK_V_W

                    return {ARMTEK_P_W: physical, ARMTEK_V_W: volumetric}

                finally:
                    await page.close()
                    await context.close()
                    await browser.close()

        except Exception as e:
            logger.error(f"‚ùå [{idx}] Proxy retry failed: {e}")
            from config import ARMTEK_P_W, ARMTEK_V_W

            return {ARMTEK_P_W: None, ARMTEK_V_W: None}

    async def _save_result(self, idx, result):
        """–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"""
        async with self.results_lock:
            for col, val in result.items():
                if pd.notna(val):
                    self.df.at[idx, col] = val

            # üî• –ü–†–û–ú–ï–ñ–£–¢–û–ß–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï –∫–∞–∂–¥—ã–µ 100 —Å—Ç—Ä–æ–∫
            if (self.processed_count + 1) % TEMP_RAW == 0:
                temp_file = f"output/temp_progress.xlsx"
                await asyncio.to_thread(self.df.to_excel, temp_file, index=False)
                logger.info(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {self.processed_count} —Å—Ç—Ä–æ–∫")

    def _build_requests(self):
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Request-–æ–≤ –¥–ª—è Crawlee
        –ö–õ–Æ–ß–ï–í–û–ï –û–¢–õ–ò–ß–ò–ï: URL —Ç–µ–ø–µ—Ä—å —Ä–µ–∞–ª—å–Ω—ã–µ!
        """
        requests = []
        logger.info(
            f"üîß _build_requests: MAX_ROWS={MAX_ROWS}, df.shape={self.df.shape}"
        )

        for idx, row in self.df.head(MAX_ROWS).iterrows():
            article = str(row[INPUT_COL_ARTICLE]).strip()

            # üÜï –õ–û–ì –ö–ê–ñ–î–û–ô –ò–¢–ï–†–ê–¶–ò–ò
            # logger.debug(f"  Loop: idx={idx}, article={article}")

            if not article:
                # logger.warning(f"  ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ idx={idx}: –ø—É—Å—Ç–æ–π –∞—Ä—Ç–∏–∫—É–ª")
                continue

            brand = str(row[INPUT_COL_BRAND]).strip()

            # ======== –í–ï–°–ê ========
            if ENABLE_WEIGHT_PARSING:
                # Japarts (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
                requests.append(
                    Request.from_url(
                        url=SiteUrls.japarts_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "japarts",
                            "task_type": "weight",
                        },
                    )
                )
                # üÜï –õ–û–ì –î–û–ë–ê–í–õ–ï–ù–ò–Ø
                # logger.info(
                #     f"  ‚úÖ Request #{len(requests)}: idx={idx}, site=japarts, part={article}"
                # )

                # Armtek (fallback - –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –µ—Å–ª–∏ Japarts –≤–µ—Ä–Ω–µ—Ç None)
                requests.append(
                    Request.from_url(
                        url=SiteUrls.armtek_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "armtek",
                            "task_type": "weight",
                        },
                    )
                )

            # ======== –ò–ú–ï–ù–ê ========
            elif ENABLE_NAME_PARSING:
                # Stparts (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
                requests.append(
                    Request.from_url(
                        url=SiteUrls.stparts_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "stparts",
                            "task_type": "name",
                        },
                    )
                )

                # Avtoformula (fallback)
                requests.append(
                    Request.from_url(
                        url=SiteUrls.avtoformula_search(brand, article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "avtoformula",
                            "task_type": "name",
                        },
                    )
                )

            # ======== –¶–ï–ù–´ ========
            elif ENABLE_PRICE_PARSING:
                # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –æ–±–∞ —Å–∞–π—Ç–∞
                requests.append(
                    Request.from_url(
                        url=SiteUrls.stparts_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "stparts",
                            "task_type": "price",
                        },
                    )
                )
                requests.append(
                    Request.from_url(
                        url=SiteUrls.avtoformula_search(brand, article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "avtoformula",
                            "task_type": "price",
                        },
                    )
                )

        return requests

    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        await self.setup()

        # üÜï –û–ß–ò–°–¢–ö–ê –ö–ï–®–ê CRAWLEE
        import shutil

        storage_dir = Path("storage")
        if storage_dir.exists():
            shutil.rmtree(storage_dir)
            logger.info("üóëÔ∏è –û—á–∏—â–µ–Ω –∫–µ—à Crawlee")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Crawler
        self.crawler = PlaywrightCrawler(
            request_handler=self.request_handler,
            max_requests_per_crawl=None,  # –ë–µ–∑ –ª–∏–º–∏—Ç–∞
            max_request_retries=3,
            # üî• –ü–†–û–°–¢–û–ô –í–ê–†–ò–ê–ù–¢ (–µ—Å–ª–∏ MAX_WORKERS=5):
            concurrency_settings=ConcurrencySettings(
                max_concurrency=MAX_WORKERS,
                desired_concurrency=MAX_WORKERS,
            ),
            headless=True,
            browser_type="chromium",
        )

        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—á–µ—Ä–µ–¥–∏
        requests = self._build_requests()
        self.total_tasks = len(requests)
        logger.info(f"üìã –ó–∞–¥–∞—á: {self.total_tasks}")

        # –ó–∞–ø—É—Å–∫
        await self.crawler.run(requests)

        # –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è
        await self._finalize()

    async def _pre_navigation_hook(self, context: PlaywrightCrawlingContext):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –î–û –Ω–∞–≤–∏–≥–∞—Ü–∏–∏ –Ω–∞ –∫–∞–∂–¥—ã–π URL
        –ó–¥–µ—Å—å –¥–µ–ª–∞–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –û–î–ò–ù —Ä–∞–∑ –¥–ª—è Avtoformula
        """
        if context.request.user_data.get("site") == "avtoformula":
            # Crawlee —Å–∞–º —É–ø—Ä–∞–≤–ª—è–µ—Ç —Å–µ—Å—Å–∏–µ–π, –ø–æ—ç—Ç–æ–º—É –ª–æ–≥–∏–Ω –Ω—É–∂–µ–Ω —Ç–æ–ª—å–∫–æ 1 —Ä–∞–∑
            if not hasattr(self, "_avtoformula_logged_in"):
                logger.info("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è Avtoformula...")
                success = await SimpleAuth.login_avtoformula(context.page)
                if success:
                    self._avtoformula_logged_in = True
                else:
                    raise Exception("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")

    async def _finalize(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        logger.info(f"üîÑ –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è ({self.mode})...")

        if ENABLE_WEIGHT_PARSING:
            self.df = await asyncio.to_thread(consolidate_weights, self.df)
            logger.info("‚úÖ –í–µ—Å–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã")

        output_file = get_output_file(self.mode)

        if ENABLE_PRICE_PARSING:
            await asyncio.to_thread(adjust_prices_and_save, self.df, output_file)
        else:
            await asyncio.to_thread(self.df.to_excel, output_file, index=False)

        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_file}")
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.processed_count}/{self.total_tasks}")


async def main():
    parser = ParserCrawler()
    await parser.run()


if __name__ == "__main__":
    asyncio.run(main())
