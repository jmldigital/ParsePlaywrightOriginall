"""
–ü–∞—Ä—Å–µ—Ä –Ω–∞ Crawlee - –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
- –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Crawlee session persistence
- URL –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–Ω–µ—Å–µ–Ω–∞ –∏–∑ —Å–∫—Ä–µ–π–ø–µ—Ä–æ–≤
- –°–∫—Ä–µ–π–ø–µ—Ä—ã –¥–µ–ª–∞—é—Ç —Ç–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥ DOM
"""

import asyncio
import sys
import io
import os
from pathlib import Path
import pandas as pd
from dotenv import load_dotenv

import asyncio
import sys
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
from crawlee import Request, ConcurrencySettings

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û:
from crawlee.crawlers import PlaywrightCrawler, PlaywrightCrawlingContext
from crawlee import Request
import logging
from crawlee.proxy_configuration import ProxyConfiguration

# UTF-8 setup
sys.stdout.reconfigure(encoding="utf-8")
sys.stderr.reconfigure(encoding="utf-8")
if os.name == "nt":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")
os.environ["PYTHONIOENCODING"] = "utf-8"

load_dotenv()

from config import (
    INPUT_FILE,
    MAX_ROWS,
    MAX_WORKERS,
    INPUT_COL_BRAND,
    INPUT_COL_ARTICLE,
    ENABLE_NAME_PARSING,
    ENABLE_WEIGHT_PARSING,
    ENABLE_PRICE_PARSING,
    AVTO_LOGIN,
    AVTO_PASSWORD,
    BAD_DETAIL_NAMES,
    SELECTORS,
    get_output_file,
    reload_config,
    TEMP_RAW,
    LOG_LEVEL,
    SAVE_INTERVAL,
    PROXY_COUNT,
    MAX_WORKERS_PROXY,
)
from utils import (
    logger,
    preprocess_dataframe,
    consolidate_weights,
    get_2captcha_proxy_pool,
    clear_debug_folders_sync,
)
from captcha_manager import CaptchaManager

# –ò–º–ø–æ—Ä—Ç –¢–û–õ–¨–ö–û –ø–∞—Ä—Å–µ—Ä–æ–≤ (–±–µ–∑ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏)
from scraper_japarts_pure import parse_weight_japarts
from scraper_armtek_pure import parse_weight_armtek
from scraper_stparts_pure import parse_stparts_name, parse_stparts_price
from scraper_avtoformula_pure import parse_avtoformula_name, parse_avtoformula_price
from price_adjuster import adjust_prices_and_save


# ===================== URL –ì–ï–ù–ï–†–ê–¢–û–†–´ =====================
class SiteUrls:
    """–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ URL –¥–ª—è –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤"""

    @staticmethod
    def japarts_search(part: str) -> str:
        return f"https://www.japarts.ru/?id=price&search={part}"

    @staticmethod
    def armtek_search(part: str) -> str:
        return f"https://armtek.ru/search?text={part}"

    @staticmethod
    def stparts_search(part: str) -> str:
        return f"https://stparts.ru/search?pcode={part}"

    @staticmethod
    def avtoformula_search(brand: str, part: str) -> str:
        # Avtoformula –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–æ—Ä–º—É –Ω–∞ –≥–ª–∞–≤–Ω–æ–π, –ø–æ—ç—Ç–æ–º—É URL = –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
        # –ü–æ–∏—Å–∫ –±—É–¥–µ—Ç —á–µ—Ä–µ–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã –≤ –ø–∞—Ä—Å–µ—Ä–µ
        return "https://www.avtoformula.ru"


# # ===================== –£–ü–†–û–©–ï–ù–ù–ê–Ø –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø =====================
# class SimpleAuth:
#     """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Crawlee session"""

#     @staticmethod
#     async def login_avtoformula(page) -> bool:
#         """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ª–æ–≥–∏–Ω–∞ - Crawlee —Å–∞–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç —Å–µ—Å—Å–∏—é"""
#         try:
#             await page.goto("https://www.avtoformula.ru")

#             # –ü—Ä–æ–≤–µ—Ä–∫–∞: —É–∂–µ –∑–∞–ª–æ–≥–∏–Ω–µ–Ω—ã?
#             if await page.locator("span:has-text('–í—ã –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –∫–∞–∫')").count() > 0:
#                 logger.info("‚úÖ –£–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã")
#                 return True

#             # –õ–æ–≥–∏–Ω
#             await page.fill(f"#{SELECTORS['avtoformula']['login_field']}", AVTO_LOGIN)
#             await page.fill(
#                 f"#{SELECTORS['avtoformula']['password_field']}", AVTO_PASSWORD
#             )
#             await page.click(SELECTORS["avtoformula"]["login_button"])

#             # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
#             await page.wait_for_selector(
#                 f"#{SELECTORS['avtoformula']['login_field']}",
#                 state="hidden",
#                 timeout=10000,
#             )

#             # –†–µ–∂–∏–º A0 (–±–µ–∑ –∞–Ω–∞–ª–æ–≥–æ–≤)
#             await page.select_option(
#                 f"#{SELECTORS['avtoformula']['smode_select']}", "A0"
#             )

#             logger.info("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
#             return True

#         except Exception as e:
#             logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
#             return False


# # ===================== –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø –° SESSION TRACKING =====================
class SimpleAuth:
    """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º —Å–µ—Å—Å–∏–π"""

    @staticmethod
    async def is_logged_in(page) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"""
        try:
            return (
                await page.locator("span:has-text('–í—ã –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –∫–∞–∫')").count() > 0
            )
        except:
            return False

    @staticmethod
    async def login_avtoformula(page, session_id: str) -> bool:
        """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ Avtoformula"""
        try:
            # –ï—Å–ª–∏ —É–∂–µ –∑–∞–ª–æ–≥–∏–Ω–µ–Ω—ã - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if await SimpleAuth.is_logged_in(page):
                logger.debug(f"‚úÖ Session {session_id}: —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∞")
                return True

            logger.info(f"üîê Session {session_id}: –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è Avtoformula...")

            # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if page.url != "https://www.avtoformula.ru/":
                await page.goto("https://www.avtoformula.ru")

            # –õ–æ–≥–∏–Ω
            await page.fill(f"#{SELECTORS['avtoformula']['login_field']}", AVTO_LOGIN)
            await page.fill(
                f"#{SELECTORS['avtoformula']['password_field']}", AVTO_PASSWORD
            )
            await page.click(SELECTORS["avtoformula"]["login_button"])

            # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            await page.wait_for_selector(
                f"#{SELECTORS['avtoformula']['login_field']}",
                state="hidden",
                timeout=10000,
            )

            # –†–µ–∂–∏–º A0 (–±–µ–∑ –∞–Ω–∞–ª–æ–≥–æ–≤)
            await page.select_option(
                f"#{SELECTORS['avtoformula']['smode_select']}", "A0"
            )

            logger.info(f"‚úÖ Session {session_id}: –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
            return True

        except Exception as e:
            logger.error(f"‚ùå Session {session_id}: –æ—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return False


# ===================== –ì–õ–ê–í–ù–´–ô –ö–õ–ê–°–° =====================
class ParserCrawler:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–∞ Crawlee"""

    def __init__(self):
        self.df = None
        self.mode = None
        self.captcha_manager = CaptchaManager()
        self.results_lock = asyncio.Lock()
        self.processed_count = 0
        self.total_tasks = 0

        # üî• –¢—Ä–µ–∫–∏–Ω–≥ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
        self.authorized_sessions = set()
        self.session_lock = asyncio.Lock()

        # üÜï –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∞–π—Ç–∞–º
        self.stats = {
            "japarts": {"total": 0, "success": 0, "empty": 0},
            "armtek": {"total": 0, "success": 0, "empty": 0},
        }

    async def setup(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        reload_config()

        # –†–µ–∂–∏–º
        active = sum([ENABLE_WEIGHT_PARSING, ENABLE_NAME_PARSING, ENABLE_PRICE_PARSING])
        if active != 1:
            raise ValueError("‚ùå –¢–æ–ª—å–∫–æ 1 —Ä–µ–∂–∏–º!")

        self.mode = (
            "–í–ï–°–ê"
            if ENABLE_WEIGHT_PARSING
            else "–ò–ú–ï–ù–ê" if ENABLE_NAME_PARSING else "–¶–ï–ù–´"
        )

        logger.info(f"‚úÖ –†–µ–∂–∏–º: {self.mode}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.df = pd.read_excel(INPUT_FILE)
        self.df = preprocess_dataframe(self.df)
        self._init_columns()

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.df)} —Å—Ç—Ä–æ–∫")

    def _init_columns(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫"""
        from config import (
            stparts_price,
            stparts_delivery,
            avtoformula_price,
            avtoformula_delivery,
            JPARTS_P_W,
            JPARTS_V_W,
            ARMTEK_P_W,
            ARMTEK_V_W,
        )

        cols = [
            stparts_price,
            stparts_delivery,
            avtoformula_price,
            avtoformula_delivery,
        ]
        for col in cols:
            if col not in self.df.columns:
                self.df[col] = None

        if ENABLE_NAME_PARSING and "finde_name" not in self.df.columns:
            self.df["finde_name"] = None

        if ENABLE_WEIGHT_PARSING:
            for col in [JPARTS_P_W, JPARTS_V_W, ARMTEK_P_W, ARMTEK_V_W]:
                if col not in self.df.columns:
                    self.df[col] = None

    async def request_handler(self, context: PlaywrightCrawlingContext):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ Crawlee - –¢–û–õ–¨–ö–û –ø–∞—Ä—Å–∏–Ω–≥"""
        page = context.page
        request = context.request
        session = context.session

        # üõë –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–æ–ø
        if Path("input/STOP.flag").exists():
            logger.warning(
                "üõë STOP.flag –Ω–∞–π–¥–µ–Ω –≤–Ω—É—Ç—Ä–∏ request_handler ‚Üí –ø—Ä–µ—Ä—ã–≤–∞–µ–º –∑–∞–¥–∞—á—É"
            )
            return  # –∏–ª–∏ raise Exception("STOP") –µ—Å–ª–∏ —Ö–æ—á–µ—à—å, —á—Ç–æ–±—ã Crawlee –Ω–µ —Ä–µ—Ç—Ä–∞–∏–ª

        idx = request.user_data["idx"]
        brand = request.user_data["brand"]
        part = request.user_data["part"]
        site = request.user_data["site"]  # üî• –û–±—ä—è–≤–ª—è–µ–º –∑–¥–µ—Å—å
        task_type = request.user_data["task_type"]

        session_id = session.id if session else "no-session"

        try:
            # üî• –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø –î–õ–Ø AVTOFORMULA
            if site == "avtoformula":
                async with self.session_lock:
                    if session_id not in self.authorized_sessions:
                        logger.debug(f"üîê [{idx}] Session {session_id}: –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")
                        success = await SimpleAuth.login_avtoformula(page, session_id)

                        if success:
                            self.authorized_sessions.add(session_id)
                            logger.debug(f"‚úÖ [{idx}] Session {session_id}: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
                        else:
                            raise Exception("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")

            # üÜï –ü–†–û–í–ï–†–ö–ê IP (–ø–µ—Ä–≤—ã–µ 3 –∑–∞–ø—Ä–æ—Å–∞)
            if not hasattr(self, "_ip_check_count"):
                self._ip_check_count = 0

            if self._ip_check_count < 3:
                try:
                    actual_ip = await page.evaluate(
                        "() => fetch('https://api.ipify.org?format=json', {timeout: 5000}).then(r => r.json()).then(d => d.ip).catch(() => 'N/A')"
                    )
                    # logger.debug(f"üåç [{idx}] IP: {actual_ip}")
                    self._ip_check_count += 1
                except:
                    pass

            # üî• –¢–û–õ–¨–ö–û –ü–ê–†–°–ò–ù–ì
            result = await self._route_to_parser(
                page, idx, brand, part, site, task_type
            )

            if result:
                await self._save_result(idx, result)

            # üî• –ü–†–û–ì–†–ï–°–° (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞)
            async with self.results_lock:
                self.processed_count += 1

                # –õ–æ–≥ –∫–∞–∂–¥—ã–µ N –∑–∞–¥–∞—á
                if self.processed_count % 50 == 0:
                    logger.info(
                        f"üìä –ü—Ä–æ–≥—Ä–µ—Å—Å: {self.processed_count}/{self.total_tasks}"
                    )

            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            async with self.results_lock:
                self.processed_count += 1
                if self.processed_count % (TEMP_RAW // 2) == 0:
                    logger.info(f"üìä {self.processed_count}/{self.total_tasks}")

        except Exception as e:
            logger.error(f"‚ùå [{idx}] {site}: {e}")
            raise

    async def _route_to_parser(self, page, idx, brand, part, site, task_type):
        """–†–æ—É—Ç–∏–Ω–≥ –∫ –Ω—É–∂–Ω–æ–º—É –ø–∞—Ä—Å–µ—Ä—É"""

        # üî• –û–ë–ù–û–í–õ–Ø–ï–ú –°–¢–ê–¢–ò–°–¢–ò–ö–£
        if site in self.stats:
            async with self.results_lock:
                self.stats[site]["total"] += 1

        # ======== –í–ï–°–ê ========
        if task_type == "weight":
            # if site == "japarts":
            #     physical, volumetric = await parse_weight_japarts(page, part, logger)

            #     if physical == "NeedCaptcha":
            #         if await self._solve_captcha(page, "japarts"):
            #             physical, volumetric = await parse_weight_japarts(
            #                 page, part, logger
            #             )

            #     from config import JPARTS_P_W, JPARTS_V_W

            #     # üÜï –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            #     if physical or volumetric:
            #         self.stats["japarts"]["success"] += 1
            #         logger.info(f"[JAPARTS] ‚úÖ {part} | P={physical} | V={volumetric}")
            #     else:
            #         self.stats["japarts"]["empty"] += 1
            #         logger.info(f"[JAPARTS] ‚ö†Ô∏è {part} | –ù–µ –Ω–∞–π–¥–µ–Ω–æ")

            #     # üÜï –î–û–ë–ê–í–ò–¢–¨ –ª–æ–≥ –î–û return:
            #     # logger.info(
            #     #     f"üîç [{idx}] Japarts RESULT ‚Üí {JPARTS_P_W}={physical}, {JPARTS_V_W}={volumetric}"
            #     # )

            #     return {JPARTS_P_W: physical, JPARTS_V_W: volumetric}

            if site == "armtek":

                physical, volumetric = await parse_weight_armtek(page, part, logger)

                # üî• RateLimit –æ–±—Ä–∞–±–æ—Ç–∫–∞
                # if physical == "NeedProxy":
                #     logger.warning(f"üö¶ [{idx}] RateLimit –Ω–∞ Armtek ‚Üí –ø—Ä–æ–∫—Å–∏ retry")
                #     return await self._retry_with_proxy(
                #         idx, brand, part, site, task_type
                #     )

                # if physical == "NeedCaptcha":
                #     if await self._solve_captcha(page, "armtek"):
                #         physical, volumetric = await parse_weight_armtek(
                #             page, part, logger
                #         )

                if physical in ["NeedCaptcha", "CloudFlare", "NeedProxy"]:
                    # üî• –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ retry (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                    retry_delay = 2  # —Å–µ–∫—É–Ω–¥—ã
                    logger.warning(
                        f"üîÑ [{idx}] {physical} ‚Üí –∑–∞–¥–µ—Ä–∂–∫–∞ {retry_delay}—Å, –∑–∞—Ç–µ–º retry"
                    )
                    await asyncio.sleep(retry_delay)
                    raise Exception(f"{physical}: retrying after {retry_delay}s")

                # üî• 1. CLOUDFLARE - —Å–±—Ä–æ—Å–∏—Ç—å –ø—Ä–æ–∫—Å–∏, retry –±–µ–∑ –ø—Ä–æ–∫—Å–∏
                # if physical == "CloudFlare":
                #     logger.warning(f"‚òÅÔ∏è [{idx}] CloudFlare –Ω–∞ Armtek ‚Üí retry –±–µ–∑ –ø—Ä–æ–∫—Å–∏")

                #     # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (Crawlee —É–∂–µ –±–µ–∑ –ø—Ä–æ–∫—Å–∏)
                #     try:
                #         await page.reload(wait_until="domcontentloaded", timeout=30000)
                #         await page.wait_for_timeout(3000)  # –ñ–¥—ë–º CloudFlare check

                #         # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                #         physical, volumetric = await parse_weight_armtek(
                #             page, part, logger
                #         )

                #         # –ï—Å–ª–∏ —Å–Ω–æ–≤–∞ CloudFlare - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                #         if physical == "CloudFlare":
                #             logger.error(f"‚òÅÔ∏è [{idx}] CloudFlare –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–µ–Ω ‚Üí –ø—Ä–æ–ø—É—Å–∫")
                #             self.stats["armtek"]["empty"] += 1
                #             from config import ARMTEK_P_W, ARMTEK_V_W

                #             return {ARMTEK_P_W: None, ARMTEK_V_W: None}

                #     except Exception as e:
                #         logger.error(f"‚ùå [{idx}] –û—à–∏–±–∫–∞ retry CloudFlare: {e}")
                #         self.stats["armtek"]["empty"] += 1
                #         from config import ARMTEK_P_W, ARMTEK_V_W

                #         return {ARMTEK_P_W: None, ARMTEK_V_W: None}

                from config import ARMTEK_P_W, ARMTEK_V_W

                # üÜï –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if physical or volumetric:
                    self.stats["armtek"]["success"] += 1
                    logger.info(f"[ARMTEK] ‚úÖ {part} | P={physical} | V={volumetric}")
                else:
                    self.stats["armtek"]["empty"] += 1
                    logger.info(f"[ARMTEK] ‚ö†Ô∏è {part} | –ù–µ –Ω–∞–π–¥–µ–Ω–æ")

                return {ARMTEK_P_W: physical, ARMTEK_V_W: volumetric}

        # ======== –ò–ú–ï–ù–ê ========
        elif task_type == "name":
            if site == "stparts":
                name = await parse_stparts_name(page, part, logger)

                if name == "NeedCaptcha":
                    if await self._solve_captcha(page, "stparts"):
                        name = await parse_stparts_name(page, part, logger)

                return (
                    {"finde_name": name}
                    if name and name not in BAD_DETAIL_NAMES
                    else None
                )

            elif site == "avtoformula":
                name = await parse_avtoformula_name(page, part, logger)

                if name == "NeedCaptcha":
                    if await self._solve_captcha(page, "avtoformula"):
                        name = await parse_avtoformula_name(page, part, logger)

                return {
                    "finde_name": (
                        name if name and name not in BAD_DETAIL_NAMES else "Detail"
                    )
                }

        # ======== –¶–ï–ù–´ ========
        elif task_type == "price":
            from config import (
                stparts_price,
                stparts_delivery,
                avtoformula_price,
                avtoformula_delivery,
            )

            if site == "stparts":
                price, delivery = await parse_stparts_price(page, brand, part, logger)

                if price == "NeedCaptcha":
                    if await self._solve_captcha(page, "stparts"):
                        price, delivery = await parse_stparts_price(
                            page, brand, part, logger
                        )

                return {stparts_price: price, stparts_delivery: delivery}

            elif site == "avtoformula":
                price, delivery = await parse_avtoformula_price(
                    page, brand, part, logger
                )

                if price == "NeedCaptcha":
                    if await self._solve_captcha(page, "avtoformula"):
                        price, delivery = await parse_avtoformula_price(
                            page, brand, part, logger
                        )

                return {avtoformula_price: price, avtoformula_delivery: delivery}

        return None

    async def _solve_captcha(self, page, site_key):
        """–†–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏"""
        logger.info(f"üîí –ö–∞–ø—á–∞ {site_key}")

        success = await self.captcha_manager.solve_captcha(
            page=page,
            logger=logger,
            site_key=site_key,
            selectors=SELECTORS.get(site_key, {}),
        )

        logger.info(f"{'‚úÖ' if success else '‚ùå'} –ö–∞–ø—á–∞ {site_key}")
        return success

    async def _save_result(self, idx, result):
        """–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"""
        async with self.results_lock:
            for col, val in result.items():
                if pd.notna(val):
                    self.df.at[idx, col] = val

            # üî• –ü–†–û–ú–ï–ñ–£–¢–û–ß–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï –∫–∞–∂–¥—ã–µ 100 —Å—Ç—Ä–æ–∫
            if (self.processed_count + 1) % TEMP_RAW == 0:
                temp_file = f"output/temp_progress.xlsx"
                await asyncio.to_thread(self.df.to_excel, temp_file, index=False)
                logger.info(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {self.processed_count} —Å—Ç—Ä–æ–∫")

    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        await self.setup()

        # üî• –°–û–ó–î–ê–Å–ú CRAWLERS –û–î–ò–ù –†–ê–ó
        WORKERS = MAX_WORKERS

        if ENABLE_WEIGHT_PARSING:
            WORKERS = MAX_WORKERS_PROXY
        else:
            WORKERS = MAX_WORKERS

        # Normal crawler (–ë–ï–ó –ø—Ä–æ–∫—Å–∏)
        normal_crawler = PlaywrightCrawler(
            request_handler=self.request_handler,
            max_request_retries=3,
            use_session_pool=True,  # ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –¥–ª—è Avtoformula
            concurrency_settings=ConcurrencySettings(
                max_concurrency=WORKERS,
                desired_concurrency=WORKERS,
                min_concurrency=2,
            ),
            headless=True,
        )

        # Proxy crawler (—Ç–æ–ª—å–∫–æ –¥–ª—è Armtek –≤ —Ä–µ–∂–∏–º–µ –í–ï–°–û–í)
        proxy_crawler = None
        if ENABLE_WEIGHT_PARSING:
            logger.info("üåê –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–∫—Å–∏ –¥–ª—è Armtek...")
            proxy_list = await asyncio.to_thread(
                get_2captcha_proxy_pool, count=PROXY_COUNT
            )

            if proxy_list:
                proxy_crawler = PlaywrightCrawler(
                    request_handler=self.request_handler,
                    proxy_configuration=ProxyConfiguration(proxy_urls=proxy_list),
                    use_session_pool=False,
                    max_request_retries=3,
                    concurrency_settings=ConcurrencySettings(
                        max_concurrency=WORKERS,
                        desired_concurrency=WORKERS,
                        min_concurrency=2,
                    ),
                    headless=True,
                )
                logger.info(f"‚úÖ Proxy crawler —Å–æ–∑–¥–∞–Ω ({len(proxy_list)} –ø—Ä–æ–∫—Å–∏)")
            else:
                logger.warning("‚ö†Ô∏è –ü—Ä–æ–∫—Å–∏ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã ‚Üí Armtek –ë–ï–ó –ø—Ä–æ–∫—Å–∏")

        # üî• –ë–ê–¢–ß-–û–ë–†–ê–ë–û–¢–ö–ê
        BATCH_SIZE = SAVE_INTERVAL
        total_rows = min(len(self.df), MAX_ROWS)
        stop_flag = Path("input/STOP.flag")

        for batch_start in range(0, total_rows, BATCH_SIZE):
            # üõë –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–æ–ø-—Ñ–ª–∞–≥–∞ –ø–µ—Ä–µ–¥ –∫–∞–∂–¥—ã–º –±–∞—Ç—á–µ–º
            if stop_flag.exists():
                logger.warning(
                    "üõë STOP.flag –Ω–∞–π–¥–µ–Ω, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä—Å–µ—Ä –ø–æ—Å–ª–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è"
                )
                break

            batch_end = min(batch_start + BATCH_SIZE, total_rows)
            batch_num = batch_start // BATCH_SIZE + 1

            logger.info(f"üì¶ –ë–ê–¢–ß #{batch_num}: —Å—Ç—Ä–æ–∫–∏ {batch_start}-{batch_end}")

            # üî• –í–´–ë–û–† –ú–ï–¢–û–î–ê –ü–û –†–ï–ñ–ò–ú–£
            if ENABLE_WEIGHT_PARSING:
                await self._process_weight_batch(
                    normal_crawler, proxy_crawler, batch_start, batch_end, batch_num
                )
            elif ENABLE_NAME_PARSING:
                await self._process_name_batch(
                    normal_crawler, batch_start, batch_end, batch_num
                )
            elif ENABLE_PRICE_PARSING:
                await self._process_price_batch(
                    normal_crawler, batch_start, batch_end, batch_num
                )

            # üíæ –ü–†–û–ú–ï–ñ–£–¢–û–ß–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï
            output_file = get_output_file(self.mode)
            await asyncio.to_thread(self.df.to_excel, output_file, index=False)
            logger.info(f"üíæ –ë–∞—Ç—á #{batch_num} —Å–æ—Ö—Ä–∞–Ω—ë–Ω ({batch_end} —Å—Ç—Ä–æ–∫)")

            # –ü–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—ã—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            await self.finalize_saved_file(
                output_file, batch_num
            )  # output_file ‚Üí input_file

        logger.info(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.processed_count} —Å—Ç—Ä–æ–∫")
        if ENABLE_NAME_PARSING or ENABLE_PRICE_PARSING:
            logger.info(
                f"üìä –í—Å–µ–≥–æ —Å–µ—Å—Å–∏–π –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ: {len(self.authorized_sessions)}"
            )

        await self._finalize()

    async def _finalize(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        logger.info(f"üîÑ –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è ({self.mode})...")

        if ENABLE_WEIGHT_PARSING:
            self.df = await asyncio.to_thread(consolidate_weights, self.df)
            logger.info("‚úÖ –í–µ—Å–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã")

        output_file = get_output_file(self.mode)

        if ENABLE_PRICE_PARSING:
            await asyncio.to_thread(adjust_prices_and_save, self.df, output_file)
        else:
            await asyncio.to_thread(self.df.to_excel, output_file, index=False)

        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_file}")
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.processed_count}/{self.total_tasks}")

    async def finalize_saved_file(self, input_file: str, batch_num: int):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —É–∂–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª"""

        logger.info(f"üîÑ –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è batch_finalize.xlsx (–±–∞—Ç—á #{batch_num})...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª
        df_final = pd.read_excel(input_file)

        if ENABLE_WEIGHT_PARSING:
            df_final = await asyncio.to_thread(consolidate_weights, df_final)
            logger.info("‚úÖ –í–µ—Å–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã")

        # üÜï –û–î–ò–ù —Ñ–∞–π–ª –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–µ–π
        batch_final_file = "output/batch_finalize.xlsx"

        if ENABLE_PRICE_PARSING:
            await asyncio.to_thread(adjust_prices_and_save, df_final, batch_final_file)
        else:
            await asyncio.to_thread(df_final.to_excel, batch_final_file, index=False)

        logger.info(f"üíæ batch_finalize.xlsx –≥–æ—Ç–æ–≤ ({len(df_final)} —Å—Ç—Ä–æ–∫)")

    async def _process_weight_batch(
        self, normal_crawler, proxy_crawler, batch_start, batch_end, batch_num
    ):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –¥–ª—è –í–ï–°–û–í: Japarts (–æ–±—ã—á–Ω—ã–π) ‚Üí Armtek (–ø—Ä–æ–∫—Å–∏)"""

        # 1Ô∏è‚É£ JAPARTS (–±–µ–∑ –ø—Ä–æ–∫—Å–∏)
        japarts_requests = []
        for idx in range(batch_start, batch_end):
            row = self.df.iloc[idx]
            article = str(row[INPUT_COL_ARTICLE]).strip()

            if not article:
                continue

            brand = str(row[INPUT_COL_BRAND]).strip()

            japarts_requests.append(
                Request.from_url(
                    url=SiteUrls.japarts_search(article),
                    user_data={
                        "idx": idx,
                        "brand": brand,
                        "part": article,
                        "site": "japarts",
                        "task_type": "weight",
                    },
                )
            )

        if japarts_requests:
            logger.info(f"  üöÄ Japarts (normal): {len(japarts_requests)} –∑–∞–¥–∞—á")
            await normal_crawler.run(japarts_requests)

        # 2Ô∏è‚É£ ARMTEK FALLBACK (–° –ü–†–û–ö–°–ò, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –≤–µ—Å –ù–ï –Ω–∞–π–¥–µ–Ω)
        from config import JPARTS_P_W

        armtek_fallback = []
        for idx in range(batch_start, batch_end):
            row = self.df.iloc[idx]

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –µ—Å—Ç—å –ª–∏ —Ñ–∏–∑–∏—á–µ—Å–∫–∏–π –≤–µ—Å —Å Japarts?
            if pd.isna(row.get(JPARTS_P_W)):
                article = str(row[INPUT_COL_ARTICLE]).strip()
                brand = str(row[INPUT_COL_BRAND]).strip()

                if article:
                    armtek_fallback.append(
                        Request.from_url(
                            url=SiteUrls.armtek_search(article),
                            user_data={
                                "idx": idx,
                                "brand": brand,
                                "part": article,
                                "site": "armtek",
                                "task_type": "weight",
                            },
                            unique_key=f"armtek_{batch_num}_{idx}",
                        )
                    )

        if armtek_fallback:
            # üî• –ò—Å–ø–æ–ª—å–∑—É–µ–º –ü–†–û–ö–°–ò crawler –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ –æ–±—ã—á–Ω—ã–π
            crawler_to_use = proxy_crawler if proxy_crawler else normal_crawler
            proxy_status = "proxy" if proxy_crawler else "–±–µ–∑ proxy"

            logger.info(
                f"  üöÄ Armtek ({proxy_status}): {len(armtek_fallback)} fallback"
            )
            await crawler_to_use.run(armtek_fallback)
        else:
            logger.info(f"  ‚úÖ –í—Å–µ —Ñ–∏–∑. –≤–µ—Å–∞ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ Japarts")

    async def _process_name_batch(self, crawler, batch_start, batch_end, batch_num):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –¥–ª—è –ò–ú–Å–ù: Stparts ‚Üí Avtoformula fallback"""

        # 1Ô∏è‚É£ STPARTS (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        stparts_requests = []
        for idx in range(batch_start, batch_end):
            row = self.df.iloc[idx]
            article = str(row[INPUT_COL_ARTICLE]).strip()

            if not article:
                continue

            brand = str(row[INPUT_COL_BRAND]).strip()

            stparts_requests.append(
                Request.from_url(
                    url=SiteUrls.stparts_search(article),
                    user_data={
                        "idx": idx,
                        "brand": brand,
                        "part": article,
                        "site": "stparts",
                        "task_type": "name",
                    },
                )
            )

        if stparts_requests:
            logger.info(f"  üöÄ Stparts: {len(stparts_requests)} –∑–∞–¥–∞—á")
            await crawler.run(stparts_requests)

        # 2Ô∏è‚É£ AVTOFORMULA FALLBACK
        avtoformula_fallback = []
        for idx in range(batch_start, batch_end):
            row = self.df.iloc[idx]

            if (
                pd.isna(row.get("finde_name"))
                or row.get("finde_name") in BAD_DETAIL_NAMES
            ):
                article = str(row[INPUT_COL_ARTICLE]).strip()
                brand = str(row[INPUT_COL_BRAND]).strip()

                if article:
                    avtoformula_fallback.append(
                        Request.from_url(
                            url=SiteUrls.avtoformula_search(brand, article),
                            user_data={
                                "idx": idx,
                                "brand": brand,
                                "part": article,
                                "site": "avtoformula",
                                "task_type": "name",
                            },
                            unique_key=f"avtoformula_{batch_num}_{idx}",
                        )
                    )

        if avtoformula_fallback:
            logger.info(
                f"  üöÄ Avtoformula fallback: {len(avtoformula_fallback)} –ø—É—Å—Ç—ã—Ö"
            )
            await crawler.run(avtoformula_fallback)
        else:
            logger.info(f"  ‚úÖ –í—Å–µ –∏–º–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ Stparts")

    async def _process_price_batch(self, crawler, batch_start, batch_end, batch_num):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –¥–ª—è –¶–ï–ù: Stparts + Avtoformula –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û"""

        all_requests = []

        for idx in range(batch_start, batch_end):
            row = self.df.iloc[idx]
            article = str(row[INPUT_COL_ARTICLE]).strip()

            if not article:
                continue

            brand = str(row[INPUT_COL_BRAND]).strip()

            # Stparts
            all_requests.append(
                Request.from_url(
                    url=SiteUrls.stparts_search(article),
                    user_data={
                        "idx": idx,
                        "brand": brand,
                        "part": article,
                        "site": "stparts",
                        "task_type": "price",
                    },
                )
            )

            # # Avtoformula
            all_requests.append(
                Request.from_url(
                    url=SiteUrls.avtoformula_search(brand, article),
                    user_data={
                        "idx": idx,
                        "brand": brand,
                        "part": article,
                        "site": "avtoformula",
                        "task_type": "price",
                    },
                    unique_key=f"avtoformula_price_{batch_num}_{idx}",
                )
            )

        if all_requests:
            logger.info(
                f"  üöÄ Stparts + Avtoformula (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ): {len(all_requests)} –∑–∞–¥–∞—á"
            )
            await crawler.run(all_requests)


async def main():
    logger.setLevel(getattr(logging, LOG_LEVEL.upper()))
    clear_debug_folders_sync(logger)
    reload_config()
    logger.info("üöÄ START: Config reloaded!")  # –î–µ–±–∞–≥
    parser = ParserCrawler()
    logger.debug("üîç –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–≤–∏–¥–Ω–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ LOG_LEVEL=DEBUG)")
    logger.info("üîç  –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–≤–∏–¥–Ω–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ LOG_LEVEL=INFO)")
    await parser.run()


if __name__ == "__main__":
    asyncio.run(main())
