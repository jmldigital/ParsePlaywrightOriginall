"""
–ü–∞—Ä—Å–µ—Ä –Ω–∞ Crawlee - –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
- –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Crawlee session persistence
- URL –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≤—ã–Ω–µ—Å–µ–Ω–∞ –∏–∑ —Å–∫—Ä–µ–π–ø–µ—Ä–æ–≤
- –°–∫—Ä–µ–π–ø–µ—Ä—ã –¥–µ–ª–∞—é—Ç —Ç–æ–ª—å–∫–æ –ø–∞—Ä—Å–∏–Ω–≥ DOM
"""

import asyncio
import sys
import io
import os
from pathlib import Path
import pandas as pd
from dotenv import load_dotenv

import asyncio
import sys
import pandas as pd
from pathlib import Path
from dotenv import load_dotenv
from crawlee import Request, ConcurrencySettings

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û:
from crawlee.crawlers import PlaywrightCrawler, PlaywrightCrawlingContext
from crawlee import Request
import logging
from crawlee.proxy_configuration import ProxyConfiguration

# UTF-8 setup
sys.stdout.reconfigure(encoding="utf-8")
sys.stderr.reconfigure(encoding="utf-8")
if os.name == "nt":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8")
os.environ["PYTHONIOENCODING"] = "utf-8"

load_dotenv()

from config import (
    INPUT_FILE,
    MAX_ROWS,
    MAX_WORKERS,
    INPUT_COL_BRAND,
    INPUT_COL_ARTICLE,
    ENABLE_NAME_PARSING,
    ENABLE_WEIGHT_PARSING,
    ENABLE_PRICE_PARSING,
    AVTO_LOGIN,
    AVTO_PASSWORD,
    BAD_DETAIL_NAMES,
    SELECTORS,
    get_output_file,
    reload_config,
    TEMP_RAW,
    LOG_LEVEL,
)
from utils import (
    logger,
    preprocess_dataframe,
    consolidate_weights,
    get_2captcha_proxy_pool,
)
from captcha_manager import CaptchaManager

# –ò–º–ø–æ—Ä—Ç –¢–û–õ–¨–ö–û –ø–∞—Ä—Å–µ—Ä–æ–≤ (–±–µ–∑ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏)
from scraper_japarts_pure import parse_weight_japarts
from scraper_armtek_pure import parse_weight_armtek
from scraper_stparts_pure import parse_stparts_name, parse_stparts_price
from scraper_avtoformula_pure import parse_avtoformula_name, parse_avtoformula_price
from price_adjuster import adjust_prices_and_save


# ===================== URL –ì–ï–ù–ï–†–ê–¢–û–†–´ =====================
class SiteUrls:
    """–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ URL –¥–ª—è –≤—Å–µ—Ö —Å–∞–π—Ç–æ–≤"""

    @staticmethod
    def japarts_search(part: str) -> str:
        return f"https://www.japarts.ru/?id=price&search={part}"

    @staticmethod
    def armtek_search(part: str) -> str:
        return f"https://armtek.ru/search?text={part}"

    @staticmethod
    def stparts_search(part: str) -> str:
        return f"https://stparts.ru/search?pcode={part}"

    @staticmethod
    def avtoformula_search(brand: str, part: str) -> str:
        # Avtoformula –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–æ—Ä–º—É –Ω–∞ –≥–ª–∞–≤–Ω–æ–π, –ø–æ—ç—Ç–æ–º—É URL = –≥–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
        # –ü–æ–∏—Å–∫ –±—É–¥–µ—Ç —á–µ—Ä–µ–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ–æ—Ä–º—ã –≤ –ø–∞—Ä—Å–µ—Ä–µ
        return "https://www.avtoformula.ru"


# # ===================== –£–ü–†–û–©–ï–ù–ù–ê–Ø –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø =====================
# class SimpleAuth:
#     """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Crawlee session"""

#     @staticmethod
#     async def login_avtoformula(page) -> bool:
#         """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ª–æ–≥–∏–Ω–∞ - Crawlee —Å–∞–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç —Å–µ—Å—Å–∏—é"""
#         try:
#             await page.goto("https://www.avtoformula.ru")

#             # –ü—Ä–æ–≤–µ—Ä–∫–∞: —É–∂–µ –∑–∞–ª–æ–≥–∏–Ω–µ–Ω—ã?
#             if await page.locator("span:has-text('–í—ã –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –∫–∞–∫')").count() > 0:
#                 logger.info("‚úÖ –£–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã")
#                 return True

#             # –õ–æ–≥–∏–Ω
#             await page.fill(f"#{SELECTORS['avtoformula']['login_field']}", AVTO_LOGIN)
#             await page.fill(
#                 f"#{SELECTORS['avtoformula']['password_field']}", AVTO_PASSWORD
#             )
#             await page.click(SELECTORS["avtoformula"]["login_button"])

#             # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
#             await page.wait_for_selector(
#                 f"#{SELECTORS['avtoformula']['login_field']}",
#                 state="hidden",
#                 timeout=10000,
#             )

#             # –†–µ–∂–∏–º A0 (–±–µ–∑ –∞–Ω–∞–ª–æ–≥–æ–≤)
#             await page.select_option(
#                 f"#{SELECTORS['avtoformula']['smode_select']}", "A0"
#             )

#             logger.info("‚úÖ –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
#             return True

#         except Exception as e:
#             logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
#             return False


# # ===================== –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø –° SESSION TRACKING =====================
class SimpleAuth:
    """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Å –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ–º —Å–µ—Å—Å–∏–π"""

    @staticmethod
    async def is_logged_in(page) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"""
        try:
            return (
                await page.locator("span:has-text('–í—ã –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –∫–∞–∫')").count() > 0
            )
        except:
            return False

    @staticmethod
    async def login_avtoformula(page, session_id: str) -> bool:
        """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ Avtoformula"""
        try:
            # –ï—Å–ª–∏ —É–∂–µ –∑–∞–ª–æ–≥–∏–Ω–µ–Ω—ã - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            if await SimpleAuth.is_logged_in(page):
                logger.debug(f"‚úÖ Session {session_id}: —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∞")
                return True

            logger.info(f"üîê Session {session_id}: –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è Avtoformula...")

            # –ü–µ—Ä–µ—Ö–æ–¥ –Ω–∞ –≥–ª–∞–≤–Ω—É—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if page.url != "https://www.avtoformula.ru/":
                await page.goto("https://www.avtoformula.ru")

            # –õ–æ–≥–∏–Ω
            await page.fill(f"#{SELECTORS['avtoformula']['login_field']}", AVTO_LOGIN)
            await page.fill(
                f"#{SELECTORS['avtoformula']['password_field']}", AVTO_PASSWORD
            )
            await page.click(SELECTORS["avtoformula"]["login_button"])

            # –ñ–¥—ë–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            await page.wait_for_selector(
                f"#{SELECTORS['avtoformula']['login_field']}",
                state="hidden",
                timeout=10000,
            )

            # –†–µ–∂–∏–º A0 (–±–µ–∑ –∞–Ω–∞–ª–æ–≥–æ–≤)
            await page.select_option(
                f"#{SELECTORS['avtoformula']['smode_select']}", "A0"
            )

            logger.info(f"‚úÖ Session {session_id}: –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞")
            return True

        except Exception as e:
            logger.error(f"‚ùå Session {session_id}: –æ—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
            return False


# ===================== –ì–õ–ê–í–ù–´–ô –ö–õ–ê–°–° =====================
class ParserCrawler:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –Ω–∞ Crawlee"""

    def __init__(self):
        self.df = None
        self.mode = None
        self.captcha_manager = CaptchaManager()
        self.results_lock = asyncio.Lock()
        self.processed_count = 0
        self.total_tasks = 0

        # üî• –¢—Ä–µ–∫–∏–Ω–≥ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–π
        self.authorized_sessions = set()
        self.session_lock = asyncio.Lock()

        # üÜï –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–∞–π—Ç–∞–º
        self.stats = {
            "japarts": {"total": 0, "success": 0, "empty": 0},
            "armtek": {"total": 0, "success": 0, "empty": 0},
        }

    async def setup(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
        reload_config()

        # –†–µ–∂–∏–º
        active = sum([ENABLE_WEIGHT_PARSING, ENABLE_NAME_PARSING, ENABLE_PRICE_PARSING])
        if active != 1:
            raise ValueError("‚ùå –¢–æ–ª—å–∫–æ 1 —Ä–µ–∂–∏–º!")

        self.mode = (
            "–í–ï–°–ê"
            if ENABLE_WEIGHT_PARSING
            else "–ò–ú–ï–ù–ê" if ENABLE_NAME_PARSING else "–¶–ï–ù–´"
        )

        logger.info(f"‚úÖ –†–µ–∂–∏–º: {self.mode}")

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.df = pd.read_excel(INPUT_FILE)
        self.df = preprocess_dataframe(self.df)
        self._init_columns()

        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.df)} —Å—Ç—Ä–æ–∫")

    def _init_columns(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫"""
        from config import (
            stparts_price,
            stparts_delivery,
            avtoformula_price,
            avtoformula_delivery,
            JPARTS_P_W,
            JPARTS_V_W,
            ARMTEK_P_W,
            ARMTEK_V_W,
        )

        cols = [
            stparts_price,
            stparts_delivery,
            avtoformula_price,
            avtoformula_delivery,
        ]
        for col in cols:
            if col not in self.df.columns:
                self.df[col] = None

        if ENABLE_NAME_PARSING and "finde_name" not in self.df.columns:
            self.df["finde_name"] = None

        if ENABLE_WEIGHT_PARSING:
            for col in [JPARTS_P_W, JPARTS_V_W, ARMTEK_P_W, ARMTEK_V_W]:
                if col not in self.df.columns:
                    self.df[col] = None

    async def request_handler(self, context: PlaywrightCrawlingContext):
        """
        –û–±—Ä–∞–±–æ—Ç—á–∏–∫ Crawlee - –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ Request
        –ü–æ–ª—É—á–∞–µ—Ç –£–ñ–ï –æ—Ç–∫—Ä—ã—Ç—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –Ω—É–∂–Ω—ã–º URL
        """
        page = context.page
        request = context.request
        session = context.session

        idx = request.user_data["idx"]
        brand = request.user_data["brand"]
        part = request.user_data["part"]
        site = request.user_data["site"]
        task_type = request.user_data["task_type"]  # "weight"/"name"/"price"

        # üî• –ü–û–õ–£–ß–ê–ï–ú ID –°–ï–°–°–ò–ò
        session_id = session.id if session else "no-session"

        # üî• –£–ü–†–û–©–Å–ù–ù–ê–Ø –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø
        if site == "avtoformula":
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º: –∑–∞–ª–æ–≥–∏–Ω–µ–Ω—ã –ª–∏?
            is_logged_in = (
                await page.locator("span:has-text('–í—ã –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –∫–∞–∫')").count() > 0
            )

            # if not is_logged_in:
            #     logger.info(f"üîê [{idx}] –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è...")
            #     await SimpleAuth.login_avtoformula(page)

        try:
            # üî• –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø –î–õ–Ø AVTOFORMULA - —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–µ—Å—Å–∏—è –µ—â—ë –Ω–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∞
            if site == "avtoformula":
                async with self.session_lock:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∞ –ª–∏ —ç—Ç–∞ —Å–µ—Å—Å–∏—è
                    if session_id not in self.authorized_sessions:
                        logger.debug(
                            f"üîê [{idx}] Session {session_id}: –ø–µ—Ä–≤–∞—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è"
                        )
                        success = await SimpleAuth.login_avtoformula(page, session_id)

                        if success:
                            # –ü–æ–º–µ—á–∞–µ–º —Å–µ—Å—Å–∏—é –∫–∞–∫ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—É—é
                            self.authorized_sessions.add(session_id)
                            logger.debug(
                                f"‚úÖ [{idx}] Session {session_id}: –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞"
                            )
                        else:
                            raise Exception("–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
                    else:
                        logger.debug(
                            f"‚úÖ [{idx}] Session {session_id}: —É–∂–µ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–∞ (–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ)"
                        )
        except Exception as e:
            logger.error(f"‚ùå [{idx}] {site}: {e}")

        # üÜï –ü–†–û–í–ï–†–ö–ê IP (—Ç–æ–ª—å–∫–æ –¥–ª—è –ø–µ—Ä–≤—ã—Ö 3 –∑–∞–ø—Ä–æ—Å–æ–≤)
        if not hasattr(self, "_ip_check_count"):
            self._ip_check_count = 0

        if self._ip_check_count < 3:
            try:
                actual_ip = await page.evaluate(
                    "() => fetch('https://api.ipify.org?format=json', {timeout: 5000}).then(r => r.json()).then(d => d.ip).catch(() => 'N/A')"
                )
                logger.debug(f"üåç [{idx}] IP –∑–∞–ø—Ä–æ—Å–∞: {actual_ip}")
                self._ip_check_count += 1
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è [{idx}] –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å IP: {e}")

            site = request.user_data["site"]

        if site == "armtek":
            proxy_info = context.proxy_info
            logger.debug(
                f"üß™ ARMTEK proxy: {proxy_info.url if proxy_info else 'NO PROXY'}"
            )

        try:
            # –í—ã–±–æ—Ä –ø–∞—Ä—Å–µ—Ä–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–∞–π—Ç–∞ –∏ –∑–∞–¥–∞—á–∏
            result = await self._route_to_parser(
                page, idx, brand, part, site, task_type
            )

            if result:
                await self._save_result(idx, result)

            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            async with self.results_lock:
                self.processed_count += 1
                if self.processed_count % TEMP_RAW / 2 == 0:
                    logger.info(f"üìä {self.processed_count}/{self.total_tasks}")

        except Exception as e:
            logger.error(f"‚ùå [{idx}] {site}: {e}")
            # Crawlee –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç

    async def _route_to_parser(self, page, idx, brand, part, site, task_type):
        """–†–æ—É—Ç–∏–Ω–≥ –∫ –Ω—É–∂–Ω–æ–º—É –ø–∞—Ä—Å–µ—Ä—É"""

        # ======== –í–ï–°–ê ========
        if task_type == "weight":
            if site == "japarts":
                physical, volumetric = await parse_weight_japarts(page, part, logger)

                if physical == "NeedCaptcha":
                    if await self._solve_captcha(page, "japarts"):
                        physical, volumetric = await parse_weight_japarts(
                            page, part, logger
                        )

                from config import JPARTS_P_W, JPARTS_V_W

                # üÜï –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if physical or volumetric:
                    self.stats["japarts"]["success"] += 1
                    logger.info(f"[JAPARTS] ‚úÖ {part} | P={physical} | V={volumetric}")
                else:
                    self.stats["japarts"]["empty"] += 1
                    logger.info(f"[JAPARTS] ‚ö†Ô∏è {part} | –ù–µ –Ω–∞–π–¥–µ–Ω–æ")

                # üÜï –î–û–ë–ê–í–ò–¢–¨ –ª–æ–≥ –î–û return:
                # logger.info(
                #     f"üîç [{idx}] Japarts RESULT ‚Üí {JPARTS_P_W}={physical}, {JPARTS_V_W}={volumetric}"
                # )

                return {JPARTS_P_W: physical, JPARTS_V_W: volumetric}

            elif site == "armtek":

                physical, volumetric = await parse_weight_armtek(page, part, logger)

                # üî• RateLimit –æ–±—Ä–∞–±–æ—Ç–∫–∞
                # if physical == "NeedProxy":
                #     logger.warning(f"üö¶ [{idx}] RateLimit –Ω–∞ Armtek ‚Üí –ø—Ä–æ–∫—Å–∏ retry")
                #     return await self._retry_with_proxy(
                #         idx, brand, part, site, task_type
                #     )

                if physical == "NeedCaptcha":
                    if await self._solve_captcha(page, "armtek"):
                        physical, volumetric = await parse_weight_armtek(
                            page, part, logger
                        )

                # üî• 1. CLOUDFLARE - —Å–±—Ä–æ—Å–∏—Ç—å –ø—Ä–æ–∫—Å–∏, retry –±–µ–∑ –ø—Ä–æ–∫—Å–∏
                if physical == "CloudFlare":
                    logger.warning(f"‚òÅÔ∏è [{idx}] CloudFlare –Ω–∞ Armtek ‚Üí retry –±–µ–∑ –ø—Ä–æ–∫—Å–∏")

                    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (Crawlee —É–∂–µ –±–µ–∑ –ø—Ä–æ–∫—Å–∏)
                    try:
                        await page.reload(wait_until="domcontentloaded", timeout=30000)
                        await page.wait_for_timeout(3000)  # –ñ–¥—ë–º CloudFlare check

                        # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
                        physical, volumetric = await parse_weight_armtek(
                            page, part, logger
                        )

                        # –ï—Å–ª–∏ —Å–Ω–æ–≤–∞ CloudFlare - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                        if physical == "CloudFlare":
                            logger.error(f"‚òÅÔ∏è [{idx}] CloudFlare –ø–µ—Ä—Å–∏—Å—Ç–µ–Ω—Ç–µ–Ω ‚Üí –ø—Ä–æ–ø—É—Å–∫")
                            self.stats["armtek"]["empty"] += 1
                            from config import ARMTEK_P_W, ARMTEK_V_W

                            return {ARMTEK_P_W: None, ARMTEK_V_W: None}

                    except Exception as e:
                        logger.error(f"‚ùå [{idx}] –û—à–∏–±–∫–∞ retry CloudFlare: {e}")
                        self.stats["armtek"]["empty"] += 1
                        from config import ARMTEK_P_W, ARMTEK_V_W

                        return {ARMTEK_P_W: None, ARMTEK_V_W: None}

                from config import ARMTEK_P_W, ARMTEK_V_W

                # üÜï –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                if physical or volumetric:
                    self.stats["armtek"]["success"] += 1
                    logger.info(f"[ARMTEK] ‚úÖ {part} | P={physical} | V={volumetric}")
                else:
                    self.stats["armtek"]["empty"] += 1
                    logger.info(f"[ARMTEK] ‚ö†Ô∏è {part} | –ù–µ –Ω–∞–π–¥–µ–Ω–æ")

                return {ARMTEK_P_W: physical, ARMTEK_V_W: volumetric}

        # ======== –ò–ú–ï–ù–ê ========
        elif task_type == "name":
            if site == "stparts":
                name = await parse_stparts_name(page, part, logger)

                if name == "NeedCaptcha":
                    if await self._solve_captcha(page, "stparts"):
                        name = await parse_stparts_name(page, part, logger)

                return (
                    {"finde_name": name}
                    if name and name not in BAD_DETAIL_NAMES
                    else None
                )

            elif site == "avtoformula":
                name = await parse_avtoformula_name(page, part, logger)

                if name == "NeedCaptcha":
                    if await self._solve_captcha(page, "avtoformula"):
                        name = await parse_avtoformula_name(page, part, logger)

                return {
                    "finde_name": (
                        name if name and name not in BAD_DETAIL_NAMES else "Detail"
                    )
                }

        # ======== –¶–ï–ù–´ ========
        elif task_type == "price":
            from config import (
                stparts_price,
                stparts_delivery,
                avtoformula_price,
                avtoformula_delivery,
            )

            if site == "stparts":
                price, delivery = await parse_stparts_price(page, brand, part, logger)
                return {stparts_price: price, stparts_delivery: delivery}

            elif site == "avtoformula":
                price, delivery = await parse_avtoformula_price(
                    page, brand, part, logger
                )
                return {avtoformula_price: price, avtoformula_delivery: delivery}

        return None

    async def _solve_captcha(self, page, site_key):
        """–†–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏"""
        logger.info(f"üîí –ö–∞–ø—á–∞ {site_key}")

        success = await self.captcha_manager.solve_captcha(
            page=page,
            logger=logger,
            site_key=site_key,
            selectors=SELECTORS.get(site_key, {}),
        )

        logger.info(f"{'‚úÖ' if success else '‚ùå'} –ö–∞–ø—á–∞ {site_key}")
        return success

    async def _save_result(self, idx, result):
        """–ü–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ"""
        async with self.results_lock:
            for col, val in result.items():
                if pd.notna(val):
                    self.df.at[idx, col] = val

            # üî• –ü–†–û–ú–ï–ñ–£–¢–û–ß–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï –∫–∞–∂–¥—ã–µ 100 —Å—Ç—Ä–æ–∫
            if (self.processed_count + 1) % TEMP_RAW == 0:
                temp_file = f"output/temp_progress.xlsx"
                await asyncio.to_thread(self.df.to_excel, temp_file, index=False)
                logger.info(f"üíæ –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ {self.processed_count} —Å—Ç—Ä–æ–∫")

    def _build_requests(self):
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ Request-–æ–≤ –¥–ª—è Crawlee
        –ö–õ–Æ–ß–ï–í–û–ï –û–¢–õ–ò–ß–ò–ï: URL —Ç–µ–ø–µ—Ä—å —Ä–µ–∞–ª—å–Ω—ã–µ!
        """
        normal_requests = []
        armtek_proxy_requests = []
        logger.info(
            f"üîß _build_requests: MAX_ROWS={MAX_ROWS}, df.shape={self.df.shape}"
        )

        for idx, row in self.df.head(MAX_ROWS).iterrows():
            article = str(row[INPUT_COL_ARTICLE]).strip()

            # üÜï –õ–û–ì –ö–ê–ñ–î–û–ô –ò–¢–ï–†–ê–¶–ò–ò
            # logger.debug(f"  Loop: idx={idx}, article={article}")

            if not article:
                # logger.warning(f"  ‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫ idx={idx}: –ø—É—Å—Ç–æ–π –∞—Ä—Ç–∏–∫—É–ª")
                continue

            brand = str(row[INPUT_COL_BRAND]).strip()

            # ======== –í–ï–°–ê ========
            if ENABLE_WEIGHT_PARSING:
                # Japarts ‚Üí –æ–±—ã—á–Ω—ã–π crawler
                normal_requests.append(
                    Request.from_url(
                        url=SiteUrls.japarts_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "japarts",
                            "task_type": "weight",
                        },
                    )
                )

                # üÜï –õ–û–ì –î–û–ë–ê–í–õ–ï–ù–ò–Ø
                # logger.info(
                #     f"  ‚úÖ Request #{len(requests)}: idx={idx}, site=japarts, part={article}"
                # )

                # Armtek (fallback - –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –µ—Å–ª–∏ Japarts –≤–µ—Ä–Ω–µ—Ç None)
                armtek_proxy_requests.append(
                    Request.from_url(
                        url=SiteUrls.armtek_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "armtek",
                            "task_type": "weight",
                        },
                    )
                )

            # ======== –ò–ú–ï–ù–ê ========
            elif ENABLE_NAME_PARSING:
                # Stparts (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
                normal_requests.append(
                    Request.from_url(
                        url=SiteUrls.stparts_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "stparts",
                            "task_type": "name",
                        },
                    )
                )

                # Avtoformula (fallback)
                # normal_requests.append(
                #     Request.from_url(
                #         url=SiteUrls.avtoformula_search(brand, article),
                #         user_data={
                #             "idx": idx,
                #             "brand": brand,
                #             "part": article,
                #             "site": "avtoformula",
                #             "task_type": "name",
                #         },
                #         # üî• –£–ù–ò–ö–ê–õ–¨–ù–´–ô ID –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                #         unique_key=f"avtoformula_{idx}_{article}",
                #     )
                # )

            # ======== –¶–ï–ù–´ ========
            elif ENABLE_PRICE_PARSING:
                # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –æ–±–∞ —Å–∞–π—Ç–∞
                normal_requests.append(
                    Request.from_url(
                        url=SiteUrls.stparts_search(article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "stparts",
                            "task_type": "price",
                        },
                    )
                )
                normal_requests.append(
                    Request.from_url(
                        url=SiteUrls.avtoformula_search(brand, article),
                        user_data={
                            "idx": idx,
                            "brand": brand,
                            "part": article,
                            "site": "avtoformula",
                            "task_type": "price",
                        },
                    )
                )

        return normal_requests, armtek_proxy_requests

    async def run(self):
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞"""
        await self.setup()

        # –û–ß–ò–°–¢–ö–ê –ö–ï–®–ê
        import shutil
        import time

        storage_dir = Path("storage")
        if storage_dir.exists():
            try:
                shutil.rmtree(storage_dir)
                logger.info("üóëÔ∏è –û—á–∏—â–µ–Ω –∫–µ—à Crawlee")
            except PermissionError:
                logger.warning("‚ö†Ô∏è –ö–µ—à –∑–∞–Ω—è—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–∏—Å—Ç–∫—É...")

        # üî• –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø –î–û CRAWLER (—Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–ª–∞–≥)
        if ENABLE_NAME_PARSING or ENABLE_PRICE_PARSING:
            self._avtoformula_needs_auth = True
        else:
            self._avtoformula_needs_auth = False

        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
        normal_requests, armtek_requests = self._build_requests()

        # üî• –†–ê–ó–î–ï–õ–Ø–ï–ú –ø–æ —Å–∞–π—Ç–∞–º
        stparts_requests = [
            r for r in normal_requests if r.user_data.get("site") == "stparts"
        ]
        japarts_requests = [
            r for r in normal_requests if r.user_data.get("site") == "japarts"
        ]

        logger.debug(f"üìã Normal tasks: {len(normal_requests)}")
        logger.debug(f"üìã Armtek proxy tasks: {len(armtek_requests)}")

        # –ü–†–û–ö–°–ò —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å Armtek –∑–∞–¥–∞—á–∏
        proxy_list = []
        proxy_crawler = None

        if ENABLE_WEIGHT_PARSING and armtek_requests:
            logger.info("üåê –†–µ–∂–∏–º –í–ï–°–ê ‚Üí –∑–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–∫—Å–∏ –¥–ª—è Armtek...")
            proxy_list = await asyncio.to_thread(get_2captcha_proxy_pool, count=5)

            if proxy_list:
                proxy_crawler = PlaywrightCrawler(
                    request_handler=self.request_handler,
                    proxy_configuration=ProxyConfiguration(proxy_urls=proxy_list),
                    use_session_pool=False,
                    max_request_retries=3,
                    concurrency_settings=ConcurrencySettings(
                        max_concurrency=MAX_WORKERS // 2,
                        desired_concurrency=MAX_WORKERS // 2,
                    ),
                    headless=True,
                )
                logger.info(f"‚úÖ Proxy crawler —Å–æ–∑–¥–∞–Ω ({len(proxy_list)} –ø—Ä–æ–∫—Å–∏)")
            else:
                logger.warning("‚ö†Ô∏è –ü—Ä–æ–∫—Å–∏ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã ‚Üí Armtek –ø–æ–π–¥—ë—Ç –ë–ï–ó –ø—Ä–æ–∫—Å–∏")

        # Normal crawler (–ë–ï–ó browser_pool_options)
        normal_crawler = PlaywrightCrawler(
            request_handler=self.request_handler,
            max_request_retries=3,
            use_session_pool=True,  # ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            concurrency_settings=ConcurrencySettings(
                max_concurrency=MAX_WORKERS,
                desired_concurrency=MAX_WORKERS,
            ),
            headless=True,
        )

        # –ó–ê–ü–£–°–ö
        if ENABLE_WEIGHT_PARSING and armtek_requests:
            if proxy_crawler:
                logger.info("üöÄ –°–Ω–∞—á–∞–ª–∞ Armtek (proxy)")
                await proxy_crawler.run(armtek_requests)
            else:
                logger.info("üöÄ –°–Ω–∞—á–∞–ª–∞ Armtek (–±–µ–∑ proxy)")
                await normal_crawler.run(armtek_requests)

        # 2Ô∏è‚É£ –ò–ú–ï–ù–ê: —Å–Ω–∞—á–∞–ª–∞ Stparts, –ø–æ—Ç–æ–º Avtoformula (fallback)
        elif ENABLE_NAME_PARSING:
            if stparts_requests:
                logger.info(f"üöÄ –≠—Ç–∞–ø 1: Stparts ({len(stparts_requests)} –∑–∞–¥–∞—á)")
                await normal_crawler.run(stparts_requests)

            # üî• FALLBACK: Avtoformula —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—É—Å—Ç—ã—Ö
            avtoformula_fallback = []
            for idx, row in self.df.iterrows():
                if (
                    pd.isna(row.get("finde_name"))
                    or row.get("finde_name") in BAD_DETAIL_NAMES
                ):
                    brand = str(row[INPUT_COL_BRAND]).strip()
                    article = str(row[INPUT_COL_ARTICLE]).strip()

                    if article:
                        avtoformula_fallback.append(
                            Request.from_url(
                                url=SiteUrls.avtoformula_search(brand, article),
                                user_data={
                                    "idx": idx,
                                    "brand": brand,
                                    "part": article,
                                    "site": "avtoformula",
                                    "task_type": "name",
                                },
                                unique_key=f"avtoformula_fallback_{idx}",
                            )
                        )

            if avtoformula_fallback:
                logger.info(
                    f"üöÄ –≠—Ç–∞–ø 2: Avtoformula fallback ({len(avtoformula_fallback)} –ø—É—Å—Ç—ã—Ö)"
                )
                await normal_crawler.run(avtoformula_fallback)
            else:
                logger.info("‚úÖ –í—Å–µ –∏–º–µ–Ω–∞ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ Stparts")

            if normal_requests:
                logger.info("üöÄ –ó–∞—Ç–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Å–∞–π—Ç—ã (normal)")
                await normal_crawler.run(normal_requests)

        # üî• –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–π
        logger.info(
            f"üìä –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–µ—Å—Å–∏–π –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–æ: {len(self.authorized_sessions)}"
        )

        await self._finalize()

    async def _finalize(self):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        logger.info(f"üîÑ –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è ({self.mode})...")

        if ENABLE_WEIGHT_PARSING:
            self.df = await asyncio.to_thread(consolidate_weights, self.df)
            logger.info("‚úÖ –í–µ—Å–∞ –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–æ–≤–∞–Ω—ã")

        output_file = get_output_file(self.mode)

        if ENABLE_PRICE_PARSING:
            await asyncio.to_thread(adjust_prices_and_save, self.df, output_file)
        else:
            await asyncio.to_thread(self.df.to_excel, output_file, index=False)

        logger.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {output_file}")
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {self.processed_count}/{self.total_tasks}")


async def main():
    logger.setLevel(getattr(logging, LOG_LEVEL.upper()))
    parser = ParserCrawler()
    logger.debug("üîç –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–≤–∏–¥–Ω–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ LOG_LEVEL=DEBUG)")
    logger.info("üîç  –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–≤–∏–¥–Ω–∞ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ LOG_LEVEL=INFO)")
    await parser.run()


if __name__ == "__main__":
    asyncio.run(main())
